import { authService } from './authService';
import { codexService } from './codexService';
import { AIRequest, AIResponse, ImageRequest, ImageResponse } from '../../types';

export class AIServiceProxy {
  private codexAvailable: boolean | null = null;

  async generateText(request: AIRequest): Promise<AIResponse> {
    // Check if Codex is available (cache the result)
    if (this.codexAvailable === null) {
      this.codexAvailable = await codexService.isCodexInstalled();
      console.log('Codex available:', this.codexAvailable);
    }

    // Prefer Codex if available
    if (this.codexAvailable) {
      console.log('Using Codex CLI for AI request');
      return await codexService.generateText(request);
    }

    // Fallback to configured provider
    const provider = localStorage.getItem('ai_provider') || 'github';

    if (provider === 'anthropic') {
      return await this.callAnthropicAPI(request);
    } else if (provider === 'openai') {
      return await this.callOpenAIAPI(request);
    } else if (provider === 'openai-oauth' || provider === 'github') {
      // Use backend for both GitHub Models and OpenAI OAuth
      // Backend will automatically route to the correct provider based on user's auth
      return await authService.makeAIRequest(
        request.prompt,
        request.context,
        request.maxTokens,
        request.temperature
      );
    } else {
      // Default to GitHub Models
      return await authService.makeAIRequest(
        request.prompt,
        request.context,
        request.maxTokens,
        request.temperature
      );
    }
  }

  private async callAnthropicAPI(request: AIRequest): Promise<AIResponse> {
    const apiKey = localStorage.getItem('anthropic_api_key');
    if (!apiKey) {
      throw new Error('Anthropic API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì • íƒ­ì—ì„œ API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.');
    }

    const prompt = request.context
      ? `${request.context}\n\n${request.prompt}`
      : request.prompt;

    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': apiKey,
        'anthropic-version': '2023-06-01',
      },
      body: JSON.stringify({
        model: 'claude-3-5-sonnet-20241022',
        max_tokens: request.maxTokens || 1024,
        temperature: request.temperature || 0.7,
        messages: [
          {
            role: 'user',
            content: prompt,
          },
        ],
      }),
    });

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error?.message || 'Anthropic API ì˜¤ë¥˜');
    }

    const data = await response.json();
    return {
      text: data.content[0].text,
      usage: {
        promptTokens: data.usage.input_tokens,
        completionTokens: data.usage.output_tokens,
        totalTokens: data.usage.input_tokens + data.usage.output_tokens,
      },
    };
  }

  private async callOpenAIAPI(request: AIRequest): Promise<AIResponse> {
    const apiKey = localStorage.getItem('openai_api_key');
    if (!apiKey) {
      throw new Error('OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì • íƒ­ì—ì„œ API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.');
    }

    const prompt = request.context
      ? `${request.context}\n\n${request.prompt}`
      : request.prompt;

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: 'gpt-4-turbo-preview',
        max_tokens: request.maxTokens || 1024,
        temperature: request.temperature || 0.7,
        messages: [
          {
            role: 'user',
            content: prompt,
          },
        ],
      }),
    });

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error?.message || 'OpenAI API ì˜¤ë¥˜');
    }

    const data = await response.json();
    return {
      text: data.choices[0].message.content,
      usage: {
        promptTokens: data.usage.prompt_tokens,
        completionTokens: data.usage.completion_tokens,
        totalTokens: data.usage.total_tokens,
      },
    };
  }

  // Helper methods for writing tasks
  async improveText(text: string): Promise<string> {
    const response = await this.generateText({
      prompt: `ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë” ë‚˜ì€ ë¬¸ì¥ìœ¼ë¡œ ê°œì„ í•´ì£¼ì„¸ìš”. ì›ë˜ì˜ ì˜ë¯¸ì™€ í†¤ì€ ìœ ì§€í•˜ë˜, ë¬¸ë²•ê³¼ í‘œí˜„ì„ í–¥ìƒì‹œì¼œì£¼ì„¸ìš”:\n\n${text}`,
      maxTokens: 1024,
    });
    return response.text;
  }

  async continueStory(context: string): Promise<string> {
    const response = await this.generateText({
      prompt: 'ì´ì•¼ê¸°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”.',
      context: context,
      maxTokens: 2048,
      temperature: 0.8,
    });
    return response.text;
  }

  async generateCharacter(description: string): Promise<string> {
    const response = await this.generateText({
      prompt: `ë‹¤ìŒ ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ ìºë¦­í„°ì˜ ìƒì„¸í•œ í”„ë¡œí•„ì„ ì‘ì„±í•´ì£¼ì„¸ìš” (ì´ë¦„, ë‚˜ì´, ì„±ê²©, ë°°ê²½ ë“±):\n\n${description}`,
      maxTokens: 1024,
    });
    return response.text;
  }

  async generatePlotIdeas(premise: string): Promise<string> {
    const response = await this.generateText({
      prompt: `ë‹¤ìŒ ì „ì œë¥¼ ë°”íƒ•ìœ¼ë¡œ 5ê°œì˜ í”Œë¡¯ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”:\n\n${premise}`,
      maxTokens: 1536,
      temperature: 0.9,
    });
    return response.text;
  }

  async generateImage(request: ImageRequest): Promise<ImageResponse> {
    // Image generation using OpenAI DALL-E 3
    const apiKey = localStorage.getItem('openai_api_key');
    if (!apiKey) {
      throw new Error('ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•´ì„œëŠ” OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.\nì„¤ì • íƒ­ì—ì„œ OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.');
    }

    console.log('ğŸ¨ DALL-E 3 ì´ë¯¸ì§€ ìƒì„± ìš”ì²­:', request.prompt);

    const response = await fetch('https://api.openai.com/v1/images/generations', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: 'dall-e-3',
        prompt: request.prompt,
        n: 1,
        size: request.size || '1024x1024',
        quality: request.quality || 'standard',
        style: request.style || 'vivid',
      }),
    });

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error?.message || 'DALL-E ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜');
    }

    const data = await response.json();
    return {
      url: data.data[0].url,
      revisedPrompt: data.data[0].revised_prompt,
    };
  }
}

// Export singleton instance (now provider-agnostic)
export const claudeServiceProxy = new AIServiceProxy();
export const openaiServiceProxy = new AIServiceProxy(); // Same instance, kept for compatibility
